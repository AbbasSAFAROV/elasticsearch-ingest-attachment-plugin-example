# This config ingests a CSV file with 2 columns: id and content to ElasticSearch as if each row was a single document
# A sample CSV:
#   id,issue
#   1,i1
#   2,i2  2
#   3,i3  4 4 5 5
#   4,"Hi, there!"
# A new document will be created in ElasticSearch index with id as file1_issue_%{id}
#
# To run this:
# 1. Change filename in config below (at two places).
# 2. Replace "id" with first column nae from CSV
# 3. Make sure ElasticSearch settings are all right.
# 4. Execute [/work/elk/logstash/logstash-5.4.0]$ ./bin/logstash -f /work/github/elasticsearch-ingest-attachment-plugin-example/logstash_configs/ingestCSV.conf
#
input {
  file {
    path => ["/work/elk/logstash/logstash-5.4.0/file1.csv"]
    sincedb_path => "/dev/null"
    start_position => "beginning"
    codec => plain {
      charset => "ISO-8859-1"
    }
    type => "policy"
  }
}

filter {
  # Drop all empty lines
  if [message] =~ /^$/ {
    drop { }
  }

  # Parse CSV rows to JSON objects
  csv {
    columns => ["id", "content"]
    add_field => {
      "isEnabled" => true
      "filename" => "file1_issue_%{id}"
      "language" => "en"
      "content_type" => "text/plain; charset=ISO-8859-1"
    }
    convert => { "isEnabled" => "boolean" }
  }

  # Drop header row
  # Replace string "id" with the first column name in CSV file
  if ([id] == "id") {
    drop { }
  }

  # Remove unncessary fields
  mutate {
    remove_field => [ "id", "host", "path" ]
  }

  # Make fields in a nested architecture
  mutate {
    rename => { "language" => "[attachment][language]" }
    rename => { "content" => "[attachment][content]" }
    rename => { "content_type" => "[attachment][content_type]" }
  }
}

output {
#  stdout { codec => rubydebug }

  elasticsearch {
    hosts => ["localhost:9200"]
    index => "policies"
    document_id => "%{filename}"
  }
}

